<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Mission Control</title>
  <style>
    * { margin: 0; padding: 0; box-sizing: border-box; }
    html, body { height: 100%; }
    body { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif; background: #0a0a0a; color: #e0e0e0; }
    .container { display: flex; height: 100vh; }
    .sidebar { width: 360px; border-right: 1px solid #222; background: linear-gradient(to bottom, #0a0a0a, #1a1a1a); overflow-y: auto; padding: 24px; display: flex; flex-direction: column; }
    .sidebar h1 { font-size: 24px; margin: 0 0 8px; color: #fff; display: flex; align-items: center; gap: 8px; }
    .sidebar > .subtitle { font-size: 12px; color: #888; margin-bottom: 24px; }
    .tabs { display: flex; gap: 12px; margin-bottom: 24px; }
    .tab { padding: 8px 16px; border-radius: 8px; background: #1a1a1a; border: 1px solid #222; cursor: pointer; font-size: 12px; font-weight: 600; transition: all 0.2s; }
    .tab.active { background: #3b82f6; border-color: #3b82f6; color: #fff; }
    .search-box { margin-bottom: 24px; }
    .search-box input { width: 100%; padding: 10px 12px; border-radius: 8px; background: #1a1a1a; border: 1px solid #222; color: #e0e0e0; font-size: 14px; }
    .sidebar-section h3 { font-size: 11px; text-transform: uppercase; color: #888; margin: 20px 0 12px; letter-spacing: 1px; }
    .doc-list { display: flex; flex-direction: column; gap: 8px; }
    .doc-item { padding: 12px; border-radius: 8px; background: #1a1a1a; border: 1px solid #222; cursor: pointer; transition: all 0.2s; }
    .doc-item:hover { background: #242424; border-color: #3b82f6; }
    .doc-item.active { background: #3b82f6; border-color: #3b82f6; color: #fff; }
    .doc-title { font-weight: 600; font-size: 13px; margin-bottom: 4px; }
    .doc-meta { font-size: 11px; color: #888; }
    .doc-item.active .doc-meta { color: rgba(255,255,255,0.7); }
    .tags-section { margin-bottom: 24px; }
    .tags-section h3 { font-size: 11px; text-transform: uppercase; color: #888; margin-bottom: 12px; letter-spacing: 1px; }
    .tag-pill { display: inline-block; padding: 4px 12px; border-radius: 12px; background: rgba(59, 130, 246, 0.2); border: 1px solid #3b82f6; color: #3b82f6; font-size: 11px; margin-right: 6px; margin-bottom: 6px; cursor: pointer; transition: all 0.2s; }
    .tag-pill:hover { background: rgba(59, 130, 246, 0.3); }
    .tag-pill.active { background: #3b82f6; color: #fff; border-color: #3b82f6; }
    .main { flex: 1; border-left: 1px solid #222; padding: 40px; overflow-y: auto; display: flex; flex-direction: column; }
    .main-empty { display: flex; align-items: center; justify-content: center; height: 100%; color: #888; font-size: 16px; }
    .doc-content { line-height: 1.6; }
    .doc-content h1 { font-size: 28px; margin: 0 0 12px; color: #fff; }
    .doc-header { margin-bottom: 32px; padding-bottom: 24px; border-bottom: 1px solid #222; }
    .doc-tags { display: flex; flex-wrap: wrap; gap: 6px; margin-top: 12px; }
    .tag { display: inline-block; background: rgba(59, 130, 246, 0.2); color: #3b82f6; padding: 4px 12px; border-radius: 12px; font-size: 11px; }
    .doc-body p { margin-bottom: 16px; }
    .doc-body h2 { font-size: 20px; margin: 32px 0 16px; color: #fff; }
    .doc-body h3 { font-size: 16px; margin: 24px 0 12px; color: #fff; }
    .doc-body ul, .doc-body ol { margin: 16px 0 16px 24px; }
    .doc-body li { margin-bottom: 8px; }
    .doc-body code { background: #1a1a1a; padding: 2px 6px; border-radius: 4px; font-family: monospace; font-size: 14px; }
    .doc-body pre { background: #1a1a1a; padding: 16px; border-radius: 8px; overflow-x: auto; margin: 16px 0; }
    .doc-body pre code { background: none; padding: 0; }
    .people-grid { display: grid; grid-template-columns: 1fr; gap: 16px; }
    .person-card { background: #1a1a1a; border: 1px solid #222; border-radius: 8px; padding: 16px; }
    .person-name { font-size: 16px; font-weight: 600; color: #fff; margin-bottom: 8px; }
    .person-role { font-size: 12px; color: #3b82f6; margin-bottom: 12px; font-weight: 500; }
    .person-info { font-size: 12px; color: #aaa; line-height: 1.8; }
    .person-info div { margin-bottom: 4px; }
    .hidden { display: none; }
  </style>
  <link rel="manifest" href="manifest.json">
</head>
<body>
  <div class="container">
    <div class="sidebar">
      <h1>üß≠ <span>MISSION CONTROL</span></h1>
      <div class="subtitle">Knowledge atlas</div>

      <div class="tabs">
        <div class="tab active" data-tab="documents">üìñ Documents</div>
        <div class="tab" data-tab="people">üë• People</div>
      </div>

      <div id="docs-panel">
        <div class="search-box">
          <input type="text" id="search" placeholder="Search notes" />
        </div>

        <div class="tags-section">
          <h3>Tags</h3>
          <div id="tags-container"></div>
        </div>

        <div id="sections-container"></div>
      </div>

      <div id="people-panel" class="hidden">
        <div class="search-box">
          <input type="text" id="people-search" placeholder="Search people" />
        </div>
        <div id="people-container"></div>
      </div>
    </div>

    <div class="main" id="main">
      <div class="main-empty">Select a document to begin.</div>
    </div>
  </div>

  <script>
    const docs = [
      {
        slug: "journal/2026-02-14-final",
        title: "2026-02-14 (Final) ‚Äî All Systems Go Before Rome Trip",
        date: "2026-02-14",
        tags: ["journal", "daily", "deployment", "cron", "architecture"],
        content: `# 2026-02-14 (Final) ‚Äî All Systems Go Before Rome Trip

## Telegram Memory System ‚Äî ‚úÖ FULLY WIRED & CAPTURING

**Status: LIVE as of ~01:20 EST**

The missing link in our architecture: persistent semantic context that survives session compactions.

**What's Running:**
- Supabase PostgreSQL + pgvector (https://oucpashabmqeninqghhv.supabase.co)
- Cron job: Every 30 minutes, captures new Telegram messages
- Embeddings: OpenAI text-embedding-3-small
- Search function: SQL-based semantic similarity queries
- Cost: ~$1-5/month (embeddings), free Supabase tier = 100k messages

**Why this matters:**
- Session restart no longer = context loss
- Semantic search finds meaning (not just keywords)
- Automatic capture (zero manual work)
- Renzo stays sharp in calls, remembers deal context, client history

**Cron Job Details:**
- ID: e9dab4a1-d14c-458e-9a85-6f7efe914695
- Payload: Isolated agentTurn executing telegram-capture.mjs
- Status: Running, polling Telegram every 30 min
- Currently: 0 new messages (Renzo just came online)

**Key Files:**
- Setup script: /Users/cora/.openclaw/workspace/telegram-capture.mjs
- Setup guide: /Users/cora/.openclaw/workspace/TELEGRAM-MEMORY-SETUP.md
- Schema: Deployed to Supabase (tables: telegram_messages, facts)

## Cora Voice (Voice App) ‚Äî ‚úÖ DEPLOYMENT COMPLETE

**URL:** https://cora-voice.fly.dev/app (live on Fly.io)

**Feb 14 Refinements:**
- System prompt fixed: answers ONLY what's asked (no info-dumping)
- Conversation behavior: max 1-2 sentences per response
- Deployed ~01:46 EST
- All changes committed to GitHub

**Architecture at a Glance:**
- WebSocket bridge (frontend ‚Üî backend)
- Deepgram Nova-3 for STT
- OpenClaw for LLM
- ElevenLabs for TTS (voice: yM93hbw8Qtvdma2wCnJG)
- Supabase auto-archiving with embeddings

**Why useful:**
- Authority engine: Live demo for clients
- Product engine: Scalable, customer-ready
- Revenue engine: Shows enterprise sophistication

## Systems Readiness Pre-Rome Trip (Feb 15-23)

All automation running. Renzo can travel without interruption.

**Running Background Systems:**
1. **2Brain cron** ‚Äî Every 6 hours, captures work ideas, commits to GitHub
2. **Telegram memory** ‚Äî Every 30 minutes, archives messages with semantic search
3. **Heartbeat** ‚Äî Runs periodically, no longer noisy
4. **OpenClaw memory** ‚Äî Persisting across sessions

**No manual intervention required.** Systems self-maintain while Renzo is in Rome.

## Architecture Lesson: Cron Payload Types

Built a critical insight into OpenClaw cron system:

**systemEvent payloads** = text messages into session (good for announcements, reminders)
**agentTurn payloads** = run isolated agent with prompt (good for script execution, complex tasks)

**Wrong approach:** Tried systemEvent to execute telegram-capture.mjs ‚Üí didn't work
**Right approach:** Used isolated agentTurn ‚Üí works perfectly

This matters for future automation: choose payload type based on what you need executed.

## ClickUp Status ‚Äî CLEAN & ORGANIZED

**Closed:** 8 tasks (Antfarm, Discord, ElevenLabs, OpenClaw update, etc.)
**Active:** 2 tasks (Cora Copilot, Heartbeat)
**Backlog:** 2 tasks (DataForSEO MCP, PersonaPlex deployment)

**Rule established:** Only Cora's tasks in "Cora" space. Renzo's action items tracked as reminders, not assignments.

## Deployment Checklist (Pre-Rome)

- ‚úÖ Cora Voice live on Fly.io
- ‚úÖ Telegram memory capturing (cron running)
- ‚úÖ 2Brain auto-capture (6h intervals)
- ‚úÖ Heartbeat stable
- ‚úÖ Memory system persistent (survives session restarts)
- ‚úÖ ClickUp cleaned
- ‚úÖ All docs committed to GitHub

## What's Paused Until Feb 24

- **Cora Copilot** (Chrome extension) ‚Äî Ready to build, starts after Rome
- **PersonaPlex/RunPod** ‚Äî Research phase, paused
- **Lead gen program** ‚Äî Paused, resumes post-trip

## Next Phase

Feb 24: Renzo returns. Full development velocity resumes.
- Build Cora Copilot (Chrome extension for call transcription)
- Launch PersonaPlex live demo setup
- Build lead gen outreach program (email cadence, targeting, messaging)`
      },
      {
        slug: "journal/2026-02-14-systems-ready",
        title: "2026-02-14 ‚Äî Cora Voice Deployed, Telegram Memory Live, ClickUp Clean",
        date: "2026-02-14",
        tags: ["journal", "daily", "deployment", "systems"],
        content: `# 2026-02-14 ‚Äî Cora Voice Deployed, Telegram Memory Live, ClickUp Clean

## Cora Voice (Voice App) ‚Äî ‚úÖ DEPLOYED & REFINED

**URL:** https://cora-voice.fly.dev/app (live on Fly.io)

**Deployment (Feb 14, ~01:46 EST):**
- System prompt refined to answer ONLY what's asked (no info-dumping)
- Conversation behavior fixed: max 1-2 sentences per response, natural flow
- All changes committed and deployed to Fly.io

**Architecture:**
- Frontend: React + Vite (WebSocket client)
- Backend: WebSocket bridge ‚Üí Deepgram Nova-3 STT ‚Üí OpenClaw ‚Üí ElevenLabs TTS
- Database: Supabase auto-archives conversations with OpenAI embeddings
- Memory: Every input + response saved with semantic embeddings
- Search: \`/api/search\` endpoint for semantic search across past conversations
- History: \`/api/history/{sessionId}\` retrieves full conversation sessions

**Why this matters:**
- Authority engine: Live demo of AI capability
- Product engine: Scalable, customer-ready tool
- Revenue engine: Shows enterprise-grade sophistication

**Known issue:** May cut off user mid-speech (Deepgram STT timeout) ‚Äî separate tuning needed

## Telegram Memory System ‚Äî ‚úÖ LIVE & CAPTURING

**Problem solved:** Session compactions were losing Telegram chat context. Needed persistent, semantic archive.

**Solution: Supabase + OpenAI Embeddings**
- Database: PostgreSQL + pgvector for semantic search
- Automatic capture: Every 30 minutes, polls Telegram for new messages
- Storage: Message ID, chat ID, user ID, text, OpenAI embedding, timestamp
- Search: SQL function \`search_telegram_messages()\` for similarity queries

**Architecture Details:**
- Supabase project: oucpashabmqeninqghhv.supabase.co
- Tables: \`telegram_messages\` (500MB free tier ‚âà 100k messages), \`facts\` (key-value store)
- Indexes: ivfflat vector index on embeddings for fast semantic search
- Scripts: \`telegram-capture.mjs\` (execution), \`supabase-schema-setup.sql\` (schema)

**Cron job:**
- ID: e9dab4a1-d14c-458e-9a85-6f7efe914695
- Schedule: Every 30 minutes
- Payload: Isolated agentTurn (executes JavaScript)
- Status: Running, 0 new messages captured (Renzo just came online)

**Why this matters:**
- Revenue engine: Helps Renzo stay sharp in calls, retain deals
- Removes dependency on session history
- Semantic search finds context even when exact keywords don't match

**Cost:** ~$1-5/month for embeddings, free Supabase tier sufficient

## ClickUp ‚Äî ‚úÖ CLEANED & ORGANIZED

**Tasks closed (8 total):**
- Antfarm workflows
- Marketing skills
- OpenClaw version update (now 2026.2.13)
- ElevenLabs account top-up
- Discord setup
- Cora security updates
- Duplicate Copilot task
- Old Cora Voice status notes
- Elementor integration

**Active tasks (2):**
1. üö® Cora Copilot ‚Äî Chrome Extension Build (URGENT, paused until Feb 23)
2. üîÑ Heartbeat & proactive check-ins (IN PROGRESS)

**Backlog (2):**
- DataForSEO MCP Server ‚Äî Local Setup
- PersonaPlex deployment script

**Rule established:** Only track Cora's own tasks in "Cora" space. Renzo's action items become reminders, not assignments.

## System Readiness (Pre-Rome Trip)

All systems green for Renzo's Feb 15-23 travel:
- **2Brain** cron: Running every 6 hours, auto-captures work
- **Telegram memory**: Capturing every 30 minutes
- **Cora Voice**: Live and accessible (no internet dependency)
- **Heartbeat**: Stable, reliable, no more garbage output
- **Memory tracking**: Clean, no blockers

## Next Phase
Feb 24: Resume full development velocity
- Start Cora Copilot build (Chrome extension)
- PersonaPlex/RunPod live demo setup
- Lead gen outreach program architecture`
      },
      {
        slug: "journal/2026-02-14",
        title: "2026-02-14 ‚Äî Rome Trip Eve & Systems Ready",
        date: "2026-02-14",
        tags: ["journal", "daily", "rome-trip", "prep"],
        content: `# 2026-02-14 ‚Äî Rome Trip Eve & Systems Ready

## Rome Citizenship Trip Departing Tomorrow
Renzo departs **Feb 15 at 7:30 PM** (DL0230 JFK‚ÜíFCO) for Italian citizenship application.
Daughter born Feb 13, 2021 ‚Äî deadline May 31, 2026 for dichiarazione di volont√†.

**Pre-trip checklist:**
- ‚úÖ N-662 Transcription (Renzo handling for name discrepancy)
- ‚úÖ Translator booked for Feb 14
- ‚è≥ Marca da bollo (‚Ç¨250 digital stamp transfer)
- ‚úÖ Ufficio Atti Esteri appointment confirmed (Francesca Barbanti, Via Petroselli 50)
- ‚úÖ Flight confirmations (Feb 15 & Feb 23 returns)

**Key documents needed:**
- Passport, birth certificate, marriage certificate
- Daughter's birth certificate (Feb 13, NYC)
- AIRE registration proof (Renzo already registered)
- Italian translation of documents (translator handling)

## Project Status Pre-Trip
- **2Brain (Mission Control)**: ‚úÖ SHIPPED ‚Äî Cron automation running (captures work every 6h)
- **Cora Copilot**: Spec complete, ready for development
- **PersonaPlex/RunPod**: Research phase (paused during Rome trip)
- **Discord intro**: Draft pending Renzo review after return
- **OpenClaw Systems**: All nominal, heartbeat active, memory tracking clean

## Day Notes
Saturday ‚Äî quiet day. Renzo focused on Rome prep.
2Brain cron executed successfully. No blockers.
Systems will auto-capture while Renzo travels (6h intervals).

## Next Phase
Feb 24: Renzo returns from Rome. Expect update on citizenship application status.
Resume Cora Copilot build, PersonaPlex research.`
      },
      {
        slug: "journal/2026-02-13",
        title: "2026-02-13 ‚Äî 2Brain Launch + OpenClaw Research",
        date: "2026-02-13",
        tags: ["journal", "daily", "2brain", "research", "openclaw"],
        content: `# 2026-02-13 ‚Äî 2Brain Launch + OpenClaw Research Complete

## Fixed Heartbeat (Critical Fix)
- **Problem**: Ollama (llama3.2:3b) generating garbage responses when heartbeat prompt fired
- **Root cause**: Ollama confused by massive system context, started analyzing framework docs
- **Solution**: Changed heartbeat model to anthropic/claude-haiku-4-5 via gateway config.patch
- **Then**: Disabled hourly broadcasts (every: "0") ‚Äî no more noisy Telegram status messages
- **Result**: Clean, reliable system

## 2Brain (Mission Control) ‚Äî SHIPPED
Built static HTML knowledge management system for capturing ideas and concepts.

**Architecture:**
- Single \`index.html\` file (~387 lines), vanilla JS, zero dependencies
- Works offline, no build process, instant load
- Document viewer with markdown support, tag filtering, real-time search
- Dark theme (Tailwind colors), Cmd+Space launcher

**Why static HTML?**
- Next.js had React hydration issues on Safari (client fetch not firing)
- Frameworks add complexity we don't need for a KB
- Single file = easy backup, fork, deploy, modify

**GitHub Repo:** https://github.com/cora-brlvnt/mission-control

## Cron Job: Auto-Capture (Every 6 Hours)
- Fires at: 0, 6, 12, 18 hours
- Job: Reviews today's work, decisions, ideas
- Extracts:
  - New concepts/research findings
  - Project status & tasks
  - Lessons learned
- Action: Updates 2Brain index.html, commits to GitHub, announces on Telegram

## OpenClaw Research: Last 7 Days Trending
Used last30days skill + Bird CLI to pull Reddit + X data on trending OpenClaw topics.

**Top Findings (by engagement):**

1. **Sub-Agent Behavior Fixes** (86 pts) ‚Äî Users forcing agents to actually execute instead of roleplaying/planning
2. **Prompt Format Conversion** (66 pts) ‚Äî Converting human language to OpenClaw native format
3. **Local Model Tuning** (65 pts):
   - Qwen 30b: \`"no code fences unless asked; prefer strict JSON"\`
   - Devstral 24b works well with 132k context window
   - OpenClaw's heavy system prompt needs compression for local models
4. **Prompt Injection Firewalls** (58 pts) ‚Äî Security layer with credential protection + audit logging
5. **Context Bloat** (53 pts) ‚Äî Default system prompt too heavy, causing slowness

**Stats:** 14 Reddit threads (577 upvotes, 62 comments), X supplementary data, 18 articles

## macOS App Setup
- Created \`/Applications/2Brain.app\` launcher
- Launch: Cmd+Space ‚Üí "2brain"
- Terminal alias: \`2brain\` (added to ~/.zshrc)

## System Maintenance
- Updated OpenClaw: 2026.2.9 ‚Üí 2026.2.12
- Memory preserved (backed up before update)
- All systems nominal

## Active Projects Now
- **2Brain**: ‚úÖ SHIPPED (GitHub + cron + macOS app)
- **Cora Copilot**: Ready to build (Chrome extension spec done)
- **PersonaPlex/RunPod**: Research phase
- **Trigger.dev**: Account ready, workflow setup next`
      },
      {
        slug: "concepts/2brain-system",
        title: "2Brain: Static HTML Knowledge Atlas",
        tags: ["concepts", "systems", "2brain", "knowledge-management"],
        content: `# 2Brain: Static HTML Knowledge Atlas

## What It Is
A zero-dependency knowledge management system built entirely in vanilla HTML/CSS/JS. Single file, works offline, instant load, searchable.

## Why Static HTML?
After trying Next.js and hitting React hydration issues on Safari, realized the KB didn't need a framework.

**Comparison:**
- Next.js: Build complexity, hydration issues, overkill
- Static HTML: Single file, works everywhere, easy to modify

## Architecture
- **File**: \`/Users/cora/.openclaw/workspace/mission-control/index.html\` (~387 lines)
- **Data structure**: \`docs\` array with slug, title, date, tags, content
- **Features**:
  - Real-time search (title + content)
  - Tag filtering (Journal vs. Concepts)
  - Dark theme (Tailwind colors)
  - People directory (contacts with roles, emails)
  - Markdown rendering (basic: headings, lists, bold, code)

## Organization
- **Journal entries**: Daily work logs, decisions, insights (\`journal/YYYY-MM-DD\`)
- **Concepts**: Reusable knowledge, frameworks, systems (\`concepts/TOPIC\`)
- **Contacts**: People directory (relationships, emails, notes)

## Launching 2Brain
- **Spotlight**: Cmd+Space ‚Üí "2brain"
- **Terminal**: \`2brain\` (alias in ~/.zshrc)
- **Dock**: Pinnable as macOS app

## Integration with OpenClaw
Cron job (every 6 hours) automatically captures work, updates index.html, commits to GitHub.
No manual steps ‚Äî knowledge stays fresh.

## Future Enhancements
- Multi-file documents (split large entries)
- Backlink graph visualization
- Collaborative mode (CRDT-based sync)
- Mobile view optimization`
      },
      {
        slug: "concepts/openclaw-trending-findings",
        title: "OpenClaw Trending Topics: Feb 2026",
        tags: ["concepts", "research", "openclaw", "architecture"],
        content: `# OpenClaw Trending Topics: February 2026

## Research Method
Used last30days skill + Bird CLI to pull Reddit + X/Twitter data from past 7 days.
Engagement-weighted ranking (upvotes, comments, retweets).

## Top 5 Findings

### 1. Sub-Agent Behavior Fixes (86 engagement points)
**Problem**: Agents planning/thinking aloud instead of executing.
**Solution**: Force execution with explicit prompts ("Do this now. No planning.")
**Takeaway**: Training agents to act, not roleplay.

### 2. Prompt Format Conversion (66 pts)
Converting human language to OpenClaw native format.
- System context compression
- JSON-first output
- Removing preambles

### 3. Local Model Tuning (65 pts)
**Qwen 30b:** \`"no code fences unless asked; prefer strict JSON"\`
**Devstral 24b:** Works well with 132k context
**Key issue**: OpenClaw's system prompt too heavy for local models
**Fix**: Compress system context, run local models separately

### 4. Prompt Injection Firewalls (58 pts)
Security layer emerging in production systems:
- Credential protection (env vars, keys)
- Audit logging
- Input validation
- Model switching on suspicious patterns

### 5. Context Bloat (53 pts)
Default system prompt causing slowness in many deployments.
Community pushing for modular, lightweight prompts.

## Data Sources
- **Reddit**: 14 threads, 577 upvotes, 62 comments
- **X/Twitter**: Bird CLI queries (organic engagement data)
- **Web**: 18 articles on architecture, security, skills

## Strategic Implications
1. **Local models gaining traction** ‚Äî People want offline, controllable agents
2. **Security becoming standard** ‚Äî Prompt injection awareness rising
3. **Simplicity wins** ‚Äî Heavy prompts losing to compressed, focused instructions
4. **Execution over planning** ‚Äî Users want agents that *do*, not think aloud`
      },
      {
        slug: "concepts/sub-agent-behavior-fixes",
        title: "Sub-Agent Behavior: From Planning to Execution",
        tags: ["concepts", "agents", "behavior", "openclaw"],
        content: `# Sub-Agent Behavior: From Planning to Execution

## The Problem
Sub-agents often think aloud, plan, or roleplay instead of actually executing tasks.

Example bad behavior:
\`\`\`
Agent: "I'll now analyze the data... let me think about this... 
the best approach would be... in my analysis... I recommend..."
\`\`\`

## The Fix
Force execution with explicit, immediate prompts.

Example good prompt:
\`\`\`
Task: [Do this immediately. No planning, no thinking aloud.]
[Action: Get data from X]
[Action: Process with Y]
[Action: Return result to Z]
\`\`\`

## Patterns That Work
1. **Action-first language**: "Do X" not "Let's think about doing X"
2. **No thinking steps**: Remove internal monologue
3. **Explicit output format**: JSON > prose narratives
4. **Clear boundaries**: Agent knows exactly when to stop

## Why This Matters
- Token waste (thinking = no progress)
- User frustration (verbose agents feel slow)
- Determinism (execution > randomness of thought)

## In OpenClaw Context
When spawning sub-agents:
- Use task-centric language
- Remove preambles in system prompts
- Expect structured output (JSON)
- Short timeouts (force completion, no rambling)`
      },
      {
        slug: "journal/2026-02-12",
        title: "2026-02-12 ‚Äî Mission Control Build & Research",
        date: "2026-02-12",
        tags: ["journal", "daily", "mission-control"],
        content: `# 2026-02-12 ‚Äî Mission Control Build & Research

## Mission Control (2nd Brain) System
- Built and deployed Next.js 14 app
- Features: Document viewer, sidebar nav, People Directory, tag filtering
- Design: Dark theme, upgraded with 21st.dev components

## Research Completed
- Elementor WordPress integration: Custom REST endpoint approach
- PhantomBuster LinkedIn: Email-first outreach strategy
- last30days skill: Installed, Reddit research enabled

## Progress
- CONTACTS.md created with Kate Mangan, Paul Chambers
- Codex CLI installed and authenticated
- First concept doc: phantombuster-linkedin-outreach.md`
      },
      {
        slug: "journal/2026-02-12",
        title: "2026-02-12 ‚Äî Mission Control Build & Research",
        date: "2026-02-12",
        tags: ["journal", "daily", "mission-control"],
        content: `# 2026-02-12 ‚Äî Mission Control Build & Research

## Mission Control (2nd Brain) System
- Built and deployed Next.js 14 app
- Features: Document viewer, sidebar nav, People Directory, tag filtering
- Design: Dark theme, upgraded with 21st.dev components

## Research Completed
- Elementor WordPress integration: Custom REST endpoint approach
- PhantomBuster LinkedIn: Email-first outreach strategy
- last30days skill: Installed, Reddit research enabled

## Progress
- CONTACTS.md created with Kate Mangan, Paul Chambers
- Codex CLI installed and authenticated
- First concept doc: phantombuster-linkedin-outreach.md`
      },
      {
        slug: "concepts/telegram-memory-system",
        title: "Telegram Memory System: Semantic Archive with Supabase",
        tags: ["concepts", "systems", "telegram", "memory", "semantics"],
        content: `# Telegram Memory System: Semantic Archive with Supabase

## Problem
Session compactions lose Telegram chat context. Each session restart means starting fresh ‚Äî no access to conversation history or prior context.

## Solution
Persistent semantic archive with automatic capture and semantic search.

## Architecture

### Database (Supabase PostgreSQL + pgvector)
**Tables:**
- \`telegram_messages\`: (message_id, chat_id, user_id, text, embedding, timestamp)
- \`facts\`: key-value store for cached metadata

**Indexes:**
- ivfflat vector index on embeddings for fast semantic search
- B-tree index on timestamp for recency filtering

### Capture Pipeline
**Trigger:** Cron job every 30 minutes
**Payload:** \`telegram-capture.mjs\` (isolated agentTurn)
**Process:**
1. Poll Telegram API for new messages (since last capture)
2. Generate OpenAI embeddings (text-embedding-3-small)
3. Upsert to Supabase \`telegram_messages\` table
4. Update \`facts.last_message_id\` for next run

### Search
**Endpoint:** \`/api/search?q=<query>&limit=<n>\`
**Process:**
1. Embed query using same model as messages
2. Run SQL function \`search_telegram_messages()\`
3. Return top-N similar messages by cosine distance

**Example:**
\`\`\`
Query: "What did Renzo say about the Rome trip?"
‚Üí Searches semantic meaning, not exact keywords
‚Üí Finds messages about "citizenship", "Feb 15", "flight", etc.
\`\`\`

### History
**Endpoint:** \`/api/history/{sessionId}\`
**Returns:** Full conversation session (all messages + timestamps)

## Implementation Details

**Supabase Project:** oucpashabmqeninqghhv.supabase.co

**Schema setup:**
\`\`\`sql
-- Table
CREATE TABLE telegram_messages (
  id BIGSERIAL PRIMARY KEY,
  message_id TEXT UNIQUE NOT NULL,
  chat_id TEXT NOT NULL,
  user_id TEXT NOT NULL,
  text TEXT NOT NULL,
  embedding vector(1536),
  timestamp TIMESTAMPTZ DEFAULT NOW()
);

-- Vector index for similarity search
CREATE INDEX ON telegram_messages USING ivfflat (embedding vector_cosine_ops);

-- Search function
CREATE FUNCTION search_telegram_messages(
  query_embedding vector(1536),
  match_count int DEFAULT 10
) RETURNS TABLE (...) AS $$
  SELECT * FROM telegram_messages
  ORDER BY embedding <=> query_embedding
  LIMIT match_count;
$$ LANGUAGE SQL;
\`\`\`

**Cron Job:**
- ID: e9dab4a1-d14c-458e-9a85-6f7efe914695
- Schedule: Every 1800000ms (30 minutes)
- Status: Running, capturing messages automatically

## Cost
- **Supabase**: Free tier covers 500MB (‚âà100k messages)
- **OpenAI embeddings**: ~$0.02-0.05 per 1M tokens
- **Monthly**: ~$1-5 depending on volume

## Why This Works
1. **No session loss**: Context survives session compactions
2. **Semantic search**: Finds meaning, not just keywords
3. **Automatic**: Zero manual effort (cron does capture)
4. **Scalable**: Supabase handles growth automatically
5. **Privacy**: All data stays in Supabase (not leaked to OpenClaw)

## Strategic Value
- **Revenue engine**: Helps Renzo stay sharp in calls
- **Decision-making**: Instant access to past context
- **Deal retention**: Remembers client conversations
- **Proof of concept**: Demonstrates AI memory architecture`
      },
      {
        slug: "concepts/cora-voice-live-deployment",
        title: "Cora Voice: Live Deployment & Architecture",
        tags: ["concepts", "systems", "voice", "deployment", "product"],
        content: `# Cora Voice: Live Deployment & Architecture

## Overview
**Live URL:** https://cora-voice.fly.dev/app

Real-time voice conversation web app. Ask Cora questions, get instant audio responses.

## Technical Architecture

### Frontend (React + Vite)
- WebSocket client for real-time communication
- Microphone input (Web Audio API)
- Audio playback (Web Audio API speaker output)
- Dark UI matching Cora brand

### Backend (WebSocket Bridge)
Process:
1. User speaks into microphone
2. Frontend sends audio stream to WebSocket
3. Backend routes to Deepgram Nova-3 (real-time STT)
4. Deepgram returns transcription
5. Transcription sent to OpenClaw session
6. OpenClaw generates response
7. Response sent to ElevenLabs TTS
8. Audio streamed back to frontend
9. User hears Cora speak

### Components
- **STT:** Deepgram Nova-3 (fastest, most accurate)
- **LLM:** OpenClaw (Claude 3.5 Sonnet)
- **TTS:** ElevenLabs (voice: yM93hbw8Qtvdma2wCnJG, model: eleven_multilingual_v2)
- **Hosting:** Fly.io (2 regions, auto-scaling)

### Database Integration (Supabase)
**Automatic conversation archiving:**
- Every user input + response logged to Supabase
- Text stored with OpenAI embeddings
- Timestamps for session tracking

**Endpoints:**
- \`/api/search\`: Semantic search across conversations
- \`/api/history/{sessionId}\`: Full conversation retrieval

**Cost:** Minimal (~$0.02/month for embeddings)

## Deployment Details

**Fly.io Configuration:**
- App name: cora-voice
- Region: iad (closest to Connecticut)
- Memory: 256MB
- Auto-scaling: Yes

**Environment Variables:**
- OPENAI_API_KEY (for embeddings)
- TELEGRAM_BOT_TOKEN (for OpenClaw routing)
- SUPABASE_URL, SUPABASE_KEY (for archival)

**Repo:** https://github.com/cora-brlvnt/cora-voice

## Behavior (Feb 14 Refinement)

**Problem:** System was info-dumping, providing unsolicited context

**Fix:** Updated system prompt
- Answer ONLY what's asked
- Max 1-2 sentences per response
- Natural conversational tone
- No summaries unless requested
- No preambles

**Result:** Feels human, not robotic

## Known Issues
- May cut off user mid-speech (Deepgram timeout) ‚Äî separate tuning session needed
- STT sometimes misses final words in rapid speech

## Strategic Value
- **Authority engine:** Live demo of AI capability (show potential clients)
- **Product engine:** Scalable, customer-ready tool (could become paid feature)
- **Revenue engine:** Demonstrates sophistication (enterprise positioning)

## Next Steps
- Fine-tune Deepgram timeout behavior
- Add user authentication (identify repeat visitors)
- Build conversation analytics dashboard
- Monetize as premium feature (Renzo + team voice calls)`
      },
      {
        slug: "concepts/openclaw-cron-payload-patterns",
        title: "OpenClaw Cron: Choosing Payload Types (systemEvent vs agentTurn)",
        tags: ["concepts", "openclaw", "cron", "architecture", "automation"],
        content: `# OpenClaw Cron: Choosing Payload Types

## The Problem
Built Telegram memory capture automation. Tried systemEvent cron payload to execute telegram-capture.mjs script.
Result: Didn't work. systemEvent injects text into session, not shell execution.

## The Solution
Use **isolated agentTurn** instead.

## Payload Types Explained

### systemEvent (Text-based)
**Use for:** Announcements, reminders, system messages
**What it does:** Injects text into current session
**Example:**
\`\`\`json
{
  "kind": "systemEvent",
  "text": "üîî Reminder: Rome trip departs in 2 hours (7:30 PM)"
}
\`\`\`
**Limitation:** Doesn't execute code, just sends text

### agentTurn (Execution-based)
**Use for:** Script execution, complex tasks, autonomous workflows
**What it does:** Spawns isolated agent, runs arbitrary code/prompts
**Example:**
\`\`\`json
{
  "kind": "agentTurn",
  "message": "Execute telegram-capture.mjs to fetch new messages"
}
\`\`\`
**Benefit:** Full code execution, returns results back to cron

## When to Use Each

| Need | Type | Why |
|------|------|-----|
| "Send a text reminder" | systemEvent | Fast, simple, text-only |
| "Run a script" | agentTurn | Can execute code |
| "Poll an API" | agentTurn | Needs network + code |
| "Announce progress" | systemEvent | Just informational |
| "Capture/transform data" | agentTurn | Needs processing |

## Real Example: Telegram Memory Capture

**Cron job:** Every 30 minutes

**Payload (agentTurn):**
\`\`\`json
{
  "kind": "agentTurn",
  "message": "Run telegram-capture.mjs to fetch new messages from Telegram, generate embeddings, upsert to Supabase"
}
\`\`\`

**What happens:**
1. OpenClaw spawns isolated agent
2. Agent executes telegram-capture.mjs
3. Script fetches Telegram messages
4. Script generates OpenAI embeddings
5. Script upserts to Supabase
6. Results returned to cron (summary announced on Telegram)

## Key Takeaway
Match payload type to task:
- **Text delivery** ‚Üí systemEvent
- **Code execution** ‚Üí agentTurn
- **Unknown** ‚Üí Try agentTurn (more powerful)`
      },
      {
        slug: "concepts/phantombuster-linkedin-outreach",
        title: "PhantomBuster LinkedIn Outreach Strategy",
        tags: ["linkedin", "automation", "lead-gen", "phantombuster", "outreach"],
        content: `# PhantomBuster LinkedIn Outreach Strategy

## Overview
Using PhantomBuster for LinkedIn lead generation with email-first outreach.

## Why Email-First?
- LinkedIn is monitored for spam/bot activity
- Email is direct - lands in inbox, more personal
- Higher conversion - less suspicious than "add me" + message

## Workflow
1. PhantomBuster ‚Üí Extract LinkedIn profile data
2. Get email addresses (Hunter.io, Apollo, or manual research)
3. Send personalized cold emails (lemlist, Instantly, Mailshake)
4. Follow up via LinkedIn after email engagement

## Tools
- **PhantomBuster**: LinkedIn scraper + profile extractor
- **Hunter.io**: Email finding
- **lemlist**: Email sequences
- **LinkedIn**: Follow-up after email engagement

## Compliance
- Respect LinkedIn ToS (no scrapers that trigger account locks)
- Use email as primary channel
- Keep sequences short and personal`
      }
    ];

    const contacts = [
      {
        name: "Kate Mangan",
        email: "kate.mangan@aubergeresorts.com",
        relationship: "Wife",
        notes: "Auberge Resorts"
      },
      {
        name: "Paul Chambers",
        email: "pchambers@trackerproducts.com",
        notes: "Tracker Products"
      }
    ];

    let selectedDoc = null;
    let selectedTag = null;
    let searchTerm = "";

    function getAllTags() {
      const tags = new Set();
      docs.forEach(d => d.tags.forEach(t => tags.add(t)));
      return Array.from(tags).sort();
    }

    function renderTags() {
      const container = document.getElementById("tags-container");
      const allTags = getAllTags();
      container.innerHTML = "<div class=\"tag-pill " + (selectedTag === null ? "active" : "") + "\" onclick=\"selectTag(null)\">All</div>";
      allTags.forEach(tag => {
        const active = selectedTag === tag ? "active" : "";
        container.innerHTML += `<div class="tag-pill ${active}" onclick="selectTag('${tag}')">${tag}</div>`;
      });
    }

    function renderSidebar() {
      const container = document.getElementById("sections-container");
      const journals = docs.filter(d => d.tags.includes("journal"));
      const concepts = docs.filter(d => !d.tags.includes("journal"));

      container.innerHTML = "";
      
      if (journals.length) {
        container.innerHTML += "<div class=\"sidebar-section\"><h3>Journal</h3><div class=\"doc-list\">";
        journals.forEach(doc => {
          const match = matchesFilters(doc);
          const visible = match ? "" : "hidden";
          const active = selectedDoc === doc.slug ? "active" : "";
          container.innerHTML += `
            <div class="doc-item ${active} ${visible}" data-slug="${doc.slug}" onclick="selectDoc('${doc.slug}')">
              <div class="doc-title">${doc.title}</div>
              <div class="doc-meta">${doc.date || 'Concept'}</div>
            </div>
          `;
        });
        container.innerHTML += "</div></div>";
      }

      if (concepts.length) {
        container.innerHTML += "<div class=\"sidebar-section\"><h3>Concepts</h3><div class=\"doc-list\">";
        concepts.forEach(doc => {
          const match = matchesFilters(doc);
          const visible = match ? "" : "hidden";
          const active = selectedDoc === doc.slug ? "active" : "";
          container.innerHTML += `
            <div class="doc-item ${active} ${visible}" data-slug="${doc.slug}" onclick="selectDoc('${doc.slug}')">
              <div class="doc-title">${doc.title}</div>
            </div>
          `;
        });
        container.innerHTML += "</div></div>";
      }
    }

    function matchesFilters(doc) {
      const matchesSearch = searchTerm === "" || doc.title.toLowerCase().includes(searchTerm.toLowerCase());
      const matchesTag = selectedTag === null || doc.tags.includes(selectedTag);
      return matchesSearch && matchesTag;
    }

    function selectDoc(slug) {
      selectedDoc = slug;
      const doc = docs.find(d => d.slug === slug);
      if (doc) renderDoc(doc);
      renderSidebar();
    }

    function selectTag(tag) {
      selectedTag = tag;
      renderTags();
      renderSidebar();
    }

    function renderDoc(doc) {
      const tagsHtml = doc.tags.map(t => `<span class="tag">${t}</span>`).join("");
      const main = document.getElementById("main");
      main.innerHTML = `
        <div class="doc-content">
          <div class="doc-header">
            <h1>${doc.title}</h1>
            <div class="doc-tags">${tagsHtml}</div>
          </div>
          <div class="doc-body">${renderMarkdown(doc.content)}</div>
        </div>
      `;
    }

    function renderMarkdown(text) {
      let html = text
        .replace(/^# (.*?)$/gm, '<h1>$1</h1>')
        .replace(/^## (.*?)$/gm, '<h2>$1</h2>')
        .replace(/^### (.*?)$/gm, '<h3>$1</h3>')
        .replace(/\n\n/g, '</p><p>')
        .replace(/^- (.*?)$/gm, '<li>$1</li>')
        .replace(/(<li>.*?<\/li>)/s, '<ul>$1</ul>')
        .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>')
        .replace(/`(.*?)`/g, '<code>$1</code>')
        .replace(/^\n/gm, '');
      return '<p>' + html + '</p>';
    }

    function renderPeople() {
      const container = document.getElementById("people-container");
      const searchTerm = document.getElementById("people-search").value.toLowerCase();
      const filtered = contacts.filter(c => 
        c.name.toLowerCase().includes(searchTerm) || c.email.toLowerCase().includes(searchTerm)
      );
      
      container.innerHTML = "<div class=\"people-grid\">" + filtered.map(c => `
        <div class="person-card">
          <div class="person-name">${c.name}</div>
          ${c.relationship ? `<div class="person-role">${c.relationship}</div>` : ""}
          <div class="person-info">
            <div>üìß ${c.email}</div>
            ${c.notes ? `<div>üìù ${c.notes}</div>` : ""}
          </div>
        </div>
      `).join("") + "</div>";
    }

    document.querySelectorAll(".tab").forEach(tab => {
      tab.addEventListener("click", () => {
        document.querySelectorAll(".tab").forEach(t => t.classList.remove("active"));
        tab.classList.add("active");
        
        const tabName = tab.dataset.tab;
        document.getElementById("docs-panel").classList.toggle("hidden", tabName !== "documents");
        document.getElementById("people-panel").classList.toggle("hidden", tabName !== "people");
        
        if (tabName === "people") renderPeople();
      });
    });

    document.getElementById("search").addEventListener("input", (e) => {
      searchTerm = e.target.value;
      renderSidebar();
    });

    document.getElementById("people-search").addEventListener("input", () => {
      renderPeople();
    });

    renderTags();
    renderSidebar();
    if (docs.length) selectDoc(docs[0].slug);
  </script>
</body>
</html>
